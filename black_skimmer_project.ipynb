{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Skimmer (Rynchops niger) Data Exploration Of US Gulf Coast Populations\n",
    "\n",
    "## About this Project\n",
    "In this project, my focus is dedicated to analyzing the population trends of the Black Skimmer along the expansive Gulf Coast of the United States, stretching from Texas to Florida. Utilizing data collected between 2010 and 2023, my primary objective is to uncover and understand any dynamic shifts in the distribution and abundance of these bird populations over this extended timeframe. To accomplish this, I will merge two distinct datasets: the first comprises submitted checklists gleaned from the comprehensive Cornell University Ebird database, while the second stems from species counts obtained through aerial surveys of the Gulf Coast barrier islandsâ€”a collaborative endeavor led by The Water Institute. This integration of datasets will yield a more holistic comprehension of avian populations along the Gulf Coast of the US than either dataset could individually provide.\n",
    "\n",
    "The choice of the Black Skimmer is underpinned by two fundamental reasons. Firstly, my personal fascination with this species has led me to spend numerous early morning hours observing these birds gracefully skimming across the water's surface to capture fish. Secondly, and more importantly, the Black Skimmer's precarious situation warrants attention; its nesting habitat, comprising coastal sandy or gravelly bars, faces substantial threats from pollution and coastal erosion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "### Cornell University eBird Data\n",
    "\n",
    "The eBird dataset, sourced from The Cornell Lab of Ornithology, comprises checklist submissions spanning from January 2010 to November 2023, specifically gathered from Texas, Louisiana, Mississippi, Alabama, and Florida. This dataset includes detailed information on the presence  of Black Skimmers as recorded in submitted checklists. Additionally, I've procured comprehensive effort data corresponding to the same time frame, allowing for an in-depth analysis of both the occurrence patterns and the instances where Black Skimmers were not observed within these submissions.\n",
    "\n",
    "Citation: eBird Basic Dataset. Version: EBD_relNov-2023. Cornell Lab of Ornithology, Ithaca, New York. Nov 2023.\n",
    "\n",
    "[More Info: https://ebird.org/about](https://ebird.org/about)\n",
    "\n",
    "### The Water Institute Aerial Survey Data\n",
    "\n",
    "The second dataset was sourced from The Water Institute's [\"Avian Data Monitoring Portal\"](https://experience.arcgis.com/experience/010503b4c64b4ff6a7f3570220a53647/page/Project-Information/). It comprises aerial surveys conducted via fixed-wing aircraft along the Gulf Coast from 2010 to 2021. These surveys aimed to count nests and nesting pairs of various avian species, covering diverse spatial extents across different years. Conducted primarily in May and June, with exceptions in 2010 due to airspace constraints during spill response and delayed identification of survey needs in certain areas, the dataset involves meticulous nest counting and categorization by species and nesting status. It serves to assess distribution trends, relative abundance, nest quantities, and breeding statuses of these avian populations.\n",
    "\n",
    "[More Info: \"2010-2021 COLONIAL WATERBIRD DATA READ-ME\"](https://twi-aviandata.s3.amazonaws.com/avian_monitoring/dotting_information/ColibriReadMe_2010-2021_Final.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping the notebook\n",
    "\n",
    "Below are the required libraries for this project. I have installed them into a conda environment using either the conda package manager or the pip package manger when the library was not available in conda. You may also install them from this notebook by removing the # symbol in front of the install commands.\n",
    "\n",
    "Once we have installed the necessary libraries into our environment we will import them into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries to install in your environment\n",
    "#!pip install pandas\n",
    "#!pip install geopandas\n",
    "#!pip install shapely\n",
    "#!pip install simplekml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are the library imports needed for this project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "from shapely.geometry import Point, Polygon\n",
    "import simplekml\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the files into our notebook\n",
    "\n",
    "We're working with multiple files that need to be imported, cleaned and then combined.\n",
    "\n",
    "The first set are all of the eBird checklists from 01-2010 to 11-2023 in TX, LA, MS, AL and FL that contain an observation of a Black Skimmer.\n",
    "\n",
    "The second set is the sampling event data from the same time frame and locations.  This sample data is provided by eBird in conjunction with the checklist data.  This data will help us understand when Black Skimmers were NOT observed on submitted checklists.\n",
    "\n",
    "The third dataset is The Water Institute data discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing eBird data into the notebook\n",
    "\n",
    "blsk_ebird_file_paths = glob.glob('data_files/ebird_blsk_data/*.txt') # using glob to make a list for blsk observation data\n",
    "\n",
    "sample_data_file_paths = glob.glob('data_files/ebird_sampling_data/*.txt') # using glob to make a list for sample data to gauge overall bird observation effort\n",
    "\n",
    "# importing the water institute data into the notebook\n",
    "\n",
    "twi_file_path = 'data_files/the_water_institute_data/the_water_institute_20102021.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the ebird black skimmer observation data files into Pandas DataFrames for cleanup process\n",
    "\n",
    "# ebird blsk dataframe\n",
    "ebird_blsk_dfs = [] # initializing a list to store the sepearte dataframes before combining\n",
    "for fp in blsk_ebird_file_paths: # a for loop to loop through the file path list, create a dataframe, then add the dataframe to the above list\n",
    "    df = pd.read_csv(fp, sep='\\t', low_memory=False)\n",
    "    ebird_blsk_dfs.append(df)\n",
    "\n",
    "ebird_blsk_df = pd.concat(ebird_blsk_dfs, ignore_index=True) #combine all the dataframes into one single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the ebird sample data files into Pandas DataFrames for cleanup process\n",
    "\n",
    "ebird_sample_dfs = [] # initializing a list to store the sepearte dataframes before combining\n",
    "for fp in sample_data_file_paths: # a for loop to loop through the file path list, create a dataframe, then add the dataframe to the above list\n",
    "    df = pd.read_csv(fp, sep='\\t', low_memory=False)\n",
    "    ebird_sample_dfs.append(df)\n",
    "\n",
    "ebird_sample_df = pd.concat(ebird_sample_dfs, ignore_index=True) #combine all the dataframes into one single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting The Water Institute data file into a Pandas DataFrame\n",
    "\n",
    "twi_df = pd.read_csv(twi_file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Exploration\n",
    "\n",
    "Below is an initial exploration of our datasets.  My goal is to create a PLAN to do the following:\n",
    "* Reduce the size by removing unnecessary columns\n",
    "* Decide which columns need a change of datatype\n",
    "* Create a column naming convention to align all the datasets\n",
    "* Decide if I need to confine the data to a more confined location\n",
    "* Prep the datasets to be combined into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 202675 entries, 0 to 202674\n",
      "Data columns (total 50 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   GLOBAL UNIQUE IDENTIFIER    202675 non-null  object \n",
      " 1   LAST EDITED DATE            202675 non-null  object \n",
      " 2   TAXONOMIC ORDER             202675 non-null  int64  \n",
      " 3   CATEGORY                    202675 non-null  object \n",
      " 4   TAXON CONCEPT ID            202675 non-null  object \n",
      " 5   COMMON NAME                 202675 non-null  object \n",
      " 6   SCIENTIFIC NAME             202675 non-null  object \n",
      " 7   SUBSPECIES COMMON NAME      2686 non-null    object \n",
      " 8   SUBSPECIES SCIENTIFIC NAME  2686 non-null    object \n",
      " 9   EXOTIC CODE                 0 non-null       float64\n",
      " 10  OBSERVATION COUNT           202675 non-null  object \n",
      " 11  BREEDING CODE               1427 non-null    object \n",
      " 12  BREEDING CATEGORY           1427 non-null    object \n",
      " 13  BEHAVIOR CODE               1427 non-null    object \n",
      " 14  AGE/SEX                     956 non-null     object \n",
      " 15  COUNTRY                     202675 non-null  object \n",
      " 16  COUNTRY CODE                202675 non-null  object \n",
      " 17  STATE                       202675 non-null  object \n",
      " 18  STATE CODE                  202675 non-null  object \n",
      " 19  COUNTY                      202647 non-null  object \n",
      " 20  COUNTY CODE                 202647 non-null  object \n",
      " 21  IBA CODE                    52422 non-null   object \n",
      " 22  BCR CODE                    87128 non-null   float64\n",
      " 23  USFWS CODE                  15131 non-null   object \n",
      " 24  ATLAS BLOCK                 0 non-null       float64\n",
      " 25  LOCALITY                    202675 non-null  object \n",
      " 26  LOCALITY ID                 202675 non-null  object \n",
      " 27  LOCALITY TYPE               202675 non-null  object \n",
      " 28  LATITUDE                    202675 non-null  float64\n",
      " 29  LONGITUDE                   202675 non-null  float64\n",
      " 30  OBSERVATION DATE            202675 non-null  object \n",
      " 31  TIME OBSERVATIONS STARTED   198952 non-null  object \n",
      " 32  OBSERVER ID                 202675 non-null  object \n",
      " 33  SAMPLING EVENT IDENTIFIER   202675 non-null  object \n",
      " 34  PROTOCOL TYPE               202675 non-null  object \n",
      " 35  PROTOCOL CODE               202675 non-null  object \n",
      " 36  PROJECT CODE                202675 non-null  object \n",
      " 37  DURATION MINUTES            191581 non-null  float64\n",
      " 38  EFFORT DISTANCE KM          158920 non-null  float64\n",
      " 39  EFFORT AREA HA              1171 non-null    float64\n",
      " 40  NUMBER OBSERVERS            200287 non-null  float64\n",
      " 41  ALL SPECIES REPORTED        202675 non-null  int64  \n",
      " 42  GROUP IDENTIFIER            75184 non-null   object \n",
      " 43  HAS MEDIA                   202675 non-null  int64  \n",
      " 44  APPROVED                    202675 non-null  int64  \n",
      " 45  REVIEWED                    202675 non-null  int64  \n",
      " 46  REASON                      0 non-null       float64\n",
      " 47  TRIP COMMENTS               47543 non-null   object \n",
      " 48  SPECIES COMMENTS            14743 non-null   object \n",
      " 49  Unnamed: 49                 0 non-null       float64\n",
      "dtypes: float64(11), int64(5), object(34)\n",
      "memory usage: 77.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# exploring the columns and data types for the ebird_blsk_df\n",
    "ebird_blsk_df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8456498 entries, 0 to 8456497\n",
      "Data columns (total 31 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   LAST EDITED DATE           object \n",
      " 1   COUNTRY                    object \n",
      " 2   COUNTRY CODE               object \n",
      " 3   STATE                      object \n",
      " 4   STATE CODE                 object \n",
      " 5   COUNTY                     object \n",
      " 6   COUNTY CODE                object \n",
      " 7   IBA CODE                   object \n",
      " 8   BCR CODE                   float64\n",
      " 9   USFWS CODE                 object \n",
      " 10  ATLAS BLOCK                float64\n",
      " 11  LOCALITY                   object \n",
      " 12  LOCALITY ID                object \n",
      " 13  LOCALITY TYPE              object \n",
      " 14  LATITUDE                   float64\n",
      " 15  LONGITUDE                  float64\n",
      " 16  OBSERVATION DATE           object \n",
      " 17  TIME OBSERVATIONS STARTED  object \n",
      " 18  OBSERVER ID                object \n",
      " 19  SAMPLING EVENT IDENTIFIER  object \n",
      " 20  PROTOCOL TYPE              object \n",
      " 21  PROTOCOL CODE              object \n",
      " 22  PROJECT CODE               object \n",
      " 23  DURATION MINUTES           float64\n",
      " 24  EFFORT DISTANCE KM         float64\n",
      " 25  EFFORT AREA HA             float64\n",
      " 26  NUMBER OBSERVERS           float64\n",
      " 27  ALL SPECIES REPORTED       float64\n",
      " 28  GROUP IDENTIFIER           object \n",
      " 29  TRIP COMMENTS              object \n",
      " 30  Unnamed: 30                float64\n",
      "dtypes: float64(10), object(21)\n",
      "memory usage: 2.0+ GB\n"
     ]
    }
   ],
   "source": [
    "ebird_sample_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bird_nerd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
